---
title: "Lab 3: COVID-19"
subtitle: 'Ecosystem Science and Sustainability 330'
author:
  - name: '[Leona Myers](https://leonamyers.github.io/leonamyers.githib.io/)'
    email: leona18@colostate.edu
format: html
---
```{r}
library(tidyverse)
library(flextable)
library(zoo)
```
## Question 1: Public Data
The availability of open data is essential for understanding climate trends, resource management, and public health. Open access to historical and real-time data allows researchers and policy makers to track changes over time, develop models, and respond effectively to emerging challenges. 
However, when public datasets disappear or become inaccessible, it threatens transparency and scientific progress. Without independent archiving, valuable data could be lost, preventing researchers from conducting reproducible studies. Efforts like the New York Timesâ€™ COVID-19 dataset ensure that historical records remain available, supporting evidence-based decision-making.
```{r}
my.date <- as.Date("2022-02-01")
my.state <- "Colorado"
covid_data <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv")
head(covid_data)
```
## Question 2: Daily Summary
```{r}
co_covid <- covid_data %>%
  filter(state == my.state) %>%  
  group_by(county) %>%
  arrange(date, .by_group = TRUE) %>%
  mutate(new_cases = cases - lag(cases, default = first(cases)), 
         new_deaths = deaths - lag(deaths, default = first(deaths))) %>%
  ungroup()

glimpse(co_covid)
```

```{r}
worst_cumulative <- co_covid %>%
  filter(date == my.date) %>%
  arrange(desc(cases)) %>%
  head(5)

worst_cumulative
```
```{r}
worst_new_cases <- co_covid %>%
  filter(date == my.date) %>%
  arrange(desc(new_cases)) %>%
  head(5)

worst_new_cases
```
```{r}
safe_counties <- co_covid %>%
  filter(date >= my.date - 13 & date <= my.date) %>%
  group_by(county) %>%
  summarize(total_new_cases = sum(new_cases, na.rm = TRUE)) %>%
  filter(total_new_cases < 100) %>%
  arrange(county)

num_safe_counties <- nrow(safe_counties)

safe_counties
```
```{r}
summary_text <- glue::glue("
As of {my.date}, the total number of new COVID-19 cases in Colorado is {sum(worst_new_cases$new_cases, na.rm = TRUE)}.
The state has recorded a total of {sum(worst_new_cases$cases, na.rm = TRUE)} cumulative cases.
There are {num_safe_counties} counties considered 'safe' based on the 14-day new case criteria.
")

print(summary_text)
```
## Question 3: Normalizing Data
```{r}
pop_url <- "https://www2.census.gov/programs-surveys/popest/datasets/2020-2023/counties/totals/co-est2023-alldata.csv"

pop_data <- read_csv(pop_url)

glimpse(pop_data)
```

```{r}
pop_data <- pop_data |> 
  mutate(
    state_code = sprintf("%02d", as.integer(STATE)),  
    county_code = sprintf("%03d", as.integer(COUNTY)),
    fips = paste0(state_code, county_code) 
  ) |> 
  filter(county_code != "000")  

```
```{r}
pop_data <- pop_data |> mutate(fips = as.integer(fips))
co_covid <- co_covid |> mutate(fips = as.integer(fips))

combined_data <- co_covid |> 
  left_join(pop_data, by = "fips")

combined_data <- combined_data |> mutate(
  per_capita_cum_cases = cases / POPESTIMATE2021,
  per_capita_new_cases = new_cases / POPESTIMATE2021,
  per_capita_new_deaths = new_deaths / POPESTIMATE2021
)
head(combined_data)
```
The data set contains columns with '2021' or 'NAME'. The dimensions are 6 x 19.
```{r}
combined_data <- combined_data |> mutate(
  per_capita_cum_cases = cases / POPESTIMATE2021,
  per_capita_new_cases = new_cases / POPESTIMATE2021,
  per_capita_new_deaths = new_deaths / POPESTIMATE2021
)
head(combined_data)
```
```{r}
colorado_range <- combined_data |>
  filter(STNAME == "Colorado") |>
  pull(POPESTIMATE2021)
colorado_range <- range(colorado_range)
print(colorado_range)
```
The range of populations in the counties of CO were 741 to 737,287 in 2021
```{r}
combined_data_filtered <- combined_data |> 
  filter(date == as.Date("2021-01-01"))


combined_data_filtered <- combined_data_filtered |> 
  mutate(
    per_capita_cum_cases = cases / POPESTIMATE2021,
    per_capita_new_cases = new_cases / POPESTIMATE2021
  )

top_cum_cases_per_capita <- combined_data_filtered |> 
  arrange(desc(per_capita_cum_cases)) |> 
  slice_head(n = 5) |> 
  select(CTYNAME, per_capita_cum_cases)

top_new_cases_per_capita <- combined_data_filtered |> 
  arrange(desc(per_capita_new_cases)) |> 
  slice_head(n = 5) |> 
  select(CTYNAME, per_capita_new_cases)

top_cum_cases_per_capita
top_new_cases_per_capita
```
## Question 4: Rolling Thresholds
```{r}
last_14_days_data <- combined_data %>%
  filter(date >= max(date) - 14)

county_stats <- last_14_days_data %>%
  group_by(county, fips) %>%
  summarize(
    total_new_cases = sum(new_cases, na.rm = TRUE),
    population = first(POPESTIMATE2021), 
    new_cases_per_100k = (total_new_cases / population) * 100000
  ) %>%
  ungroup()

top_counties <- county_stats %>%
  arrange(desc(new_cases_per_100k)) %>%
  slice_head(n = 5)

top_counties %>%
  flextable() %>%
  set_caption("Top 5 Colorado Counties with the Most New Cases per 100k (Last 14 Days)")

counties_above_threshold <- sum(county_stats$new_cases_per_100k > 100)

counties_above_threshold

```
## Question 5: Death Toll
```{r}
covid_deaths_2021 <- combined_data %>%
  filter(date >= as.Date("2021-01-01") & date <= as.Date("2021-12-31")) %>%
  group_by(county, fips) %>%
  summarize(total_covid_deaths = sum(new_deaths, na.rm = TRUE)) %>%
  ungroup()

death_data <- covid_deaths_2021 %>%
  left_join(pop_data, by = "fips") %>%
  mutate(covid_death_percentage = (total_covid_deaths / DEATHS2021) * 100)

counties_over_20_percent <- death_data %>%
  filter(covid_death_percentage >= 20)

ggplot(counties_over_20_percent, aes(x = reorder(county, covid_death_percentage), y = covid_death_percentage)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(
    title = "Counties Where COVID Deaths Account for 20% or More of Total Deaths in 2021",
    x = "County",
    y = "Percentage of Total Deaths Attributed to COVID-19"
  ) +
  theme_minimal()
```
## Question 6: Multi-state
```{r}
state_data_all <- covid_data

states_of_interest <- c("New York", "Colorado", "Alabama", "Ohio")

state_data_all <- state_data_all %>%
  arrange(state, date) %>%
  group_by(state) %>%
  mutate(
    new_cases = cases - lag(cases, default = 0)  
  ) %>%
  ungroup()

state_data <- state_data_all %>%
  filter(state %in% states_of_interest) %>%
  group_by(state, date) %>%
  summarize(
    total_new_cases = sum(new_cases, na.rm = TRUE)  
  ) %>%
  ungroup()

state_data <- state_data %>%
  arrange(state, date) %>%
  group_by(state) %>%
  mutate(
    daily_new_cases = total_new_cases - lag(total_new_cases, default = 0),
    rolling_7_day_mean = zoo::rollmean(daily_new_cases, 7, fill = NA, align = "right")
  ) %>%
  ungroup()

head(state_data)
```
```{r}
ggplot(state_data, aes(x = date)) +

  geom_bar(aes(y = daily_new_cases), stat = "identity", fill = "lightblue", alpha = 0.6) +

  geom_line(aes(y = rolling_7_day_mean), color = "darkblue", size = 1) +
  
  facet_wrap(~state, scales = "free_y") +
  
  labs(
    title = "COVID-19 Daily New Cases and 7-Day Rolling Mean by State",
    subtitle = "Light blue bars: Daily new cases. Dark blue line: 7-day rolling average.",
    x = "Date",
    y = "Cases"
  ) +
  
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1), 
    strip.text = element_text(size = 12, face = "bold")  
  )
```
Scaling by population gives a clearer picture of the intensity or severity of COVID-19's spread in relation to the size of the population, allowing for fairer comparisons between states of different sizes. It highlights areas that may be more vulnerable relative to their population, even if their total case numbers are lower. This method is crucial for understanding where healthcare resources might be most stretched and where outbreaks may be particularly severe despite smaller total case numbers.

## Question 7: Space & Time
```{r}
counties <- read_csv("https://raw.githubusercontent.com/mikejohnson51/csu-ess-330/refs/heads/main/resources/county-centroids.csv")
head(counties)
```

```{r}
covid_with_locations <- covid_data %>%
  left_join(counties, by = "fips")

head(covid_with_locations)

```
```{r}
covid_with_locations <- covid_with_locations %>%
  mutate(month = format(date, "%m")) %>%
  group_by(date, month) %>%
  summarize(
    total_cases = sum(cases, na.rm = TRUE),
    weighted_lat = sum(LAT * cases, na.rm = TRUE) / total_cases,
    weighted_lon = sum(LON * cases, na.rm = TRUE) / total_cases
  ) %>%
  ungroup()

head(covid_with_locations)
```
```{r}
ggplot() +
  borders("state", fill = "gray90", colour = "white") +  
  geom_point(data = covid_with_locations, aes(x = weighted_lon, y = weighted_lat, size = total_cases, color = month)) +
  scale_color_viridis_d() +  
  labs(
    title = "COVID-19 Weighted Mean Center of USA Over Time",
    x = "Longitude",
    y = "Latitude",
    color = "Month",
    size = "Total Cases"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

```
The movement of the COVID-19 weighted mean center throughout the USA reflects the shifting epicenters of the outbreak, particularly in response to spikes in cases across different regions. Early on, the virus concentrated in urban areas like New York City, which drove the weighted center to the Northeast. As the pandemic progressed, hot spots emerged in different parts of the country, including the Sunbelt states during summer 2020 and in the Midwest and South later in the year. The movement of the weighted mean can be linked to factors such as population density, local government responses, public health measures, and seasonality, which influenced where cases surged at different times. For example, in the winter months, cold weather likely contributed to higher transmission rates in indoor settings, shifting the mean center toward the northern and central states.
